{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn.metrics\n",
    "import tensorflow as tf\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_data(\n",
    "    chkpt_path,\n",
    "    dataset_name = \"nyt2\",\n",
    "    encoder = \"pcnn\",\n",
    "    selector = \"att\",\n",
    "    l2_lambd = 0.0,\n",
    "    batch_size = 64):\n",
    "    data_dir = os.path.join(\"data\", dataset_name)\n",
    "    preprocessed_data_dir = get_preprocessed_dir(data_dir)\n",
    "    if not os.path.exists(preprocessed_data_dir):\n",
    "        os.mkdir(preprocessed_data_dir)\n",
    "\n",
    "    #preprocessor_batch(data_dir)\n",
    "\n",
    "    from src.model import Model\n",
    "    tf.reset_default_graph()\n",
    "    _, word_vec_mat = load_word_vec(os.path.join(\"data\", dataset_name))\n",
    "    max_classes = 53\n",
    "    model = Model(word_vec_mat, encoder = encoder, selector=selector, no_of_classes=max_classes)\n",
    "    print(\"Setting max class size to : \", max_classes)\n",
    "    train_data = load_data(preprocessed_data_dir, max_classes)\n",
    "    dev_data = load_data(preprocessed_data_dir, max_classes, \"test\")\n",
    "\n",
    "\n",
    "    n_epochs = 4\n",
    "    pair_bag_loc = train_data[-1]\n",
    "    pairs = list(pair_bag_loc.keys())\n",
    "    dev_pair_bag_loc = dev_data[-1]\n",
    "    dev_pairs = list(dev_pair_bag_loc.keys())\n",
    "    dev_pairs_dict = get_dev_pairs_dict(dev_pairs)\n",
    "    n_dev_batches = len(dev_pairs) // batch_size\n",
    "    \n",
    "    # Load model from checkpoint\n",
    "    model.mloader(os.path.join(\"saved\", \"models\", chkpt_path))\n",
    "    model.reset_optimizer()\n",
    "    \n",
    "    def na_nonNA(pairs):\n",
    "        not_NA_rels = 0\n",
    "        naPairs = []\n",
    "        nonNaPairs = []\n",
    "        for k in pairs:\n",
    "            if k.split(\"#\")[2] != \"0\":\n",
    "                nonNaPairs.append(k)\n",
    "            else:\n",
    "                naPairs.append(k)\n",
    "        return naPairs, nonNaPairs\n",
    "\n",
    "    # Store NA and nonNA pairs from train, dev.\n",
    "    trainNa, trainNonNa = na_nonNA(pairs)\n",
    "    print('Douglas#Ken' in trainNa)\n",
    "    devNa, devNonNa = na_nonNA(dev_pairs)\n",
    "    not_NA_rels = len(devNonNa)\n",
    "    trainNonNA_pairs_dict = get_dev_pairs_dict(trainNonNa)\n",
    "    trainNA_pairs_dict = get_dev_pairs_dict(trainNa)\n",
    "    print(\"Pairs in train dataset NA and non NA : \", len(trainNa), len(trainNonNa))\n",
    "    print(\"Pairs in train dataset NA and non NA : \", len(devNa), len(devNonNa))\n",
    "    \"\"\"\n",
    "    all_words, all_pos1, all_pos2, all_masks, all_lengths, \\\n",
    "    all_inst_rels, pair_bag_loc = train_data\n",
    "    all_dev_words, all_dev_pos1, all_dev_pos2, all_dev_masks, \\\n",
    "    all_dev_lengths, all_dev_inst_rels, dev_pair_bag_loc = dev_data\n",
    "    \"\"\"\n",
    "    entPairSents = {} \n",
    "        \n",
    "    import json \n",
    "    with open(os.path.join(data_dir, \"train.json\"), \"r\") as f: \n",
    "        data = json.load(f)\n",
    "        for sent in data: \n",
    "          e1 = sent['head']['word'] \n",
    "          e2 = sent['tail']['word'] \n",
    "          try: \n",
    "              rel = relToId[sent['relation']] \n",
    "          except Exception as ex: \n",
    "              rel = 0 \n",
    "          k = e1 + \"#\" + e2  \n",
    "          if k in entPairSents: \n",
    "            entPairSents[k].append(sent['sentence']) \n",
    "          else: \n",
    "            entPairSents[k] = [sent['sentence']]\n",
    "    with open(os.path.join(data_dir, \"idToRel.json\"), \"r\") as f: \n",
    "        idToRel = json.load(f)\n",
    "    \n",
    "    def dump_best_data(pairs, name = \"NonNA\"):\n",
    "        n_batches = len(pairs) // batch_size\n",
    "        test_res = []\n",
    "        print(n_batches)\n",
    "        print(\"Running model on data ...\", end = \" \")\n",
    "        for i in range(n_batches):\n",
    "          if i % 100 == 0:\n",
    "            print(i , end = \" \")\n",
    "          batch_keys = pairs[i * batch_size : (i + 1) * batch_size]\n",
    "          words, pos1, pos2, inst_rels, masks, lengths, \\\n",
    "            rels, scope = batch_maker(train_data, batch_keys)\n",
    "          pos1[pos1 > 239] = 239\n",
    "          pos2[pos2 > 239] = 239\n",
    "          pos1[pos1 < 0] = 0\n",
    "          pos2[pos2 < 0] = 0\n",
    "          output, atts = model.test_batch(words, pos1, pos2, inst_rels, \n",
    "            masks, lengths, rels, scope)\n",
    "          for i, k in enumerate(batch_keys):\n",
    "            entPair = \"#\".join(k.split(\"#\")[:2])\n",
    "            entPairRels = trainNA_pairs_dict[entPair]\n",
    "#             for j in range(1, 53):\n",
    "#               correct = 0\n",
    "#               if j in entPairRels:\n",
    "#                 correct = 1\n",
    "#               if output[i][j] > 0.01:\n",
    "#                 if correct:\n",
    "#                     test_res.append({\"entPair\" : entPair, \n",
    "#                         \"score\" : output[i][j], \n",
    "#                         \"correct\" : correct, \n",
    "#                         \"pred\" : j, \n",
    "#                         \"actual\" : entPairRels,\n",
    "#                         \"atts\" : atts[i][j] if selector is \"att\" else []})\n",
    "            j = 0\n",
    "            correct = 0\n",
    "            if j in entPairRels:\n",
    "                correct = 1\n",
    "            if output[i][j] > 0.5:\n",
    "                if correct:\n",
    "                    test_res.append({\"entPair\" : entPair, \n",
    "                        \"score\" : output[i][j], \n",
    "                        \"correct\" : correct, \n",
    "                        \"pred\" : j, \n",
    "                        \"actual\" : entPairRels,\n",
    "                        \"atts\" : atts[i][j] if selector is \"att\" else []})\n",
    "        prec = []\n",
    "        recall = []\n",
    "        correct = 0\n",
    "        sorted_test_result = sorted(test_res, key=lambda x: x['score'], reverse = True)\n",
    "\n",
    "        import time\n",
    "        start = time.time()\n",
    "\n",
    "        for i, item in enumerate(sorted_test_result):\n",
    "          if item[\"correct\"]:\n",
    "            correct += 1  \n",
    "          prec.append(float(correct) / (i + 1))\n",
    "          recall.append(float(correct) / not_NA_rels)\n",
    "        size_ = 1000\n",
    "        for j in range(50):\n",
    "            with open(os.path.join(\"saved\", \"aucs\", chkpt_path +\"_\" + name + \"_\"+ str(j) + \"_\" \"_preds.csv\"), \"w\", newline=\"\") as f:\n",
    "                preds = []\n",
    "                for i, item in enumerate(sorted_test_result[j * size_: (j + 1) * size_]):\n",
    "                    sents = \"\\n\".join(entPairSents[item[\"entPair\"]])\n",
    "                    temp_str = [item[\"entPair\"], sents, idToRel[str(item[\"pred\"])], \" \",\n",
    "                                \"\\n\".join(idToRel[str(k)] for k in item[\"actual\"]), str(item[\"correct\"]), \n",
    "                                \" \".join(str(x) for x in item[\"atts\"]), str(item[\"score\"])]\n",
    "                    preds.append(temp_str)\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(preds)\n",
    "        \n",
    "    dump_best_data(trainNa, \"NA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model with encoder and selector :  pcnn att\n",
      "121 (?, 120, 230)\n",
      "121 (?, 120, 230)\n",
      "(?, 690)\n",
      "Created model with no bootstrapping, bs val : 0.0\n",
      "<tf.Variable 'word_embedding/word_embedding:0' shape=(114042, 50) dtype=float32_ref>\n",
      "<tf.Variable 'word_embedding/unk_word_embedding:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'word_embedding/start_word_embedding:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'word_embedding/end_word_embedding:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'pos_embedding/real_pos1_embedding:0' shape=(240, 5) dtype=float32_ref>\n",
      "<tf.Variable 'pos_embedding/real_pos2_embedding:0' shape=(240, 5) dtype=float32_ref>\n",
      "<tf.Variable 'pcnn/conv1d/kernel:0' shape=(3, 60, 230) dtype=float32_ref>\n",
      "<tf.Variable 'pcnn/conv1d/bias:0' shape=(230,) dtype=float32_ref>\n",
      "<tf.Variable 'attention/logit/relation_matrix:0' shape=(53, 690) dtype=float32_ref>\n",
      "<tf.Variable 'attention/logit/bias:0' shape=(53,) dtype=float32_ref>\n",
      "<tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>\n",
      "<tf.Variable 'word_embedding/word_embedding/Adam:0' shape=(114042, 50) dtype=float32_ref>\n",
      "<tf.Variable 'word_embedding/word_embedding/Adam_1:0' shape=(114042, 50) dtype=float32_ref>\n",
      "<tf.Variable 'word_embedding/unk_word_embedding/Adam:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'word_embedding/unk_word_embedding/Adam_1:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'word_embedding/start_word_embedding/Adam:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'word_embedding/start_word_embedding/Adam_1:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'word_embedding/end_word_embedding/Adam:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'word_embedding/end_word_embedding/Adam_1:0' shape=(1, 50) dtype=float32_ref>\n",
      "<tf.Variable 'pos_embedding/real_pos1_embedding/Adam:0' shape=(240, 5) dtype=float32_ref>\n",
      "<tf.Variable 'pos_embedding/real_pos1_embedding/Adam_1:0' shape=(240, 5) dtype=float32_ref>\n",
      "<tf.Variable 'pos_embedding/real_pos2_embedding/Adam:0' shape=(240, 5) dtype=float32_ref>\n",
      "<tf.Variable 'pos_embedding/real_pos2_embedding/Adam_1:0' shape=(240, 5) dtype=float32_ref>\n",
      "<tf.Variable 'pcnn/conv1d/kernel/Adam:0' shape=(3, 60, 230) dtype=float32_ref>\n",
      "<tf.Variable 'pcnn/conv1d/kernel/Adam_1:0' shape=(3, 60, 230) dtype=float32_ref>\n",
      "<tf.Variable 'pcnn/conv1d/bias/Adam:0' shape=(230,) dtype=float32_ref>\n",
      "<tf.Variable 'pcnn/conv1d/bias/Adam_1:0' shape=(230,) dtype=float32_ref>\n",
      "<tf.Variable 'attention/logit/relation_matrix/Adam:0' shape=(53, 690) dtype=float32_ref>\n",
      "<tf.Variable 'attention/logit/relation_matrix/Adam_1:0' shape=(53, 690) dtype=float32_ref>\n",
      "<tf.Variable 'attention/logit/bias/Adam:0' shape=(53,) dtype=float32_ref>\n",
      "<tf.Variable 'attention/logit/bias/Adam_1:0' shape=(53,) dtype=float32_ref>\n",
      "Setting max class size to :  53\n",
      "Loded model from path : saved/models/pcnn_att_nyt2_none_53_n_0_0.3455\n",
      "INFO:tensorflow:Restoring parameters from saved/models/pcnn_att_nyt2_none_53_n_0_0.3455\n",
      "Resetting adam optimizer variables.\n",
      "False\n",
      "Pairs in train dataset NA and non NA :  262336 18252\n",
      "Pairs in train dataset NA and non NA :  94917 1950\n",
      "4099\n",
      "Running model on data ... 0 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b7f06964c583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbetter_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pcnn_att_nyt2_none_53_n_0_0.3455\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-53b9da52b995>\u001b[0m in \u001b[0;36mbetter_data\u001b[0;34m(chkpt_path, dataset_name, encoder, selector, l2_lambd, batch_size)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mdump_best_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainNa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-53b9da52b995>\u001b[0m in \u001b[0;36mdump_best_data\u001b[0;34m(pairs, name)\u001b[0m\n\u001b[1;32m     97\u001b[0m           \u001b[0mpos2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos2\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m           output, atts = model.test_batch(words, pos1, pos2, inst_rels, \n\u001b[0;32m---> 99\u001b[0;31m             masks, lengths, rels, scope)\n\u001b[0m\u001b[1;32m    100\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mentPair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"#\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BTP-code/src/model.py\u001b[0m in \u001b[0;36mtest_batch\u001b[0;34m(self, words, pos1, pos2, inst_rels, masks, lengths, rels, scope, learning_rate)\u001b[0m\n\u001b[1;32m    222\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasks_ph\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate_ph\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m               self.keep_prob : 1.0})\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprobabs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "better_data(\"pcnn_att_nyt2_none_53_n_0_0.3455\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
