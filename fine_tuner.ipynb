{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;\n",
    "import pandas as pd;\n",
    "import tensorflow as tf; \n",
    "tf.reset_default_graph(); \n",
    "from src.modelFt import *; \n",
    "from src.utils import *\n",
    "import math\n",
    "import random\n",
    "import seaborn\n",
    "import sys\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word vectors and get data directory\n",
    "encoder = \"pcnn\"\n",
    "selector = \"att\"\n",
    "dataset_name = \"nyt2\"\n",
    "max_classes = 53\n",
    "l2_lambd = 0.0\n",
    "_, word_vec_mat = load_word_vec(os.path.join(\"data\", \"nyt2\"))\n",
    "data_dir = os.path.join(\"data\", dataset_name)\n",
    "fname_prefix = encoder + \"_\" + selector + \"_\" + dataset_name + \"_ft_\" + str(max_classes) + \"_n_\" + str(l2_lambd) + \"_\"\n",
    "best_auc = 0.1\n",
    "preprocessed_data_dir = get_preprocessed_dir(data_dir)\n",
    "train_data = load_data(preprocessed_data_dir, max_classes)\n",
    "test_data = load_data(preprocessed_data_dir, max_classes, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data to entity pairs\n",
    "n_epochs = 2\n",
    "\n",
    "pair_bag_loc = train_data[-1]\n",
    "pairs = list(pair_bag_loc.keys())\n",
    "pairs_dict = get_dev_pairs_dict(pairs)\n",
    "n_train_batches = len(pairs) // batch_size\n",
    "\n",
    "test_pair_bag_loc = test_data[-1]\n",
    "test_pairs = list(test_pair_bag_loc.keys())\n",
    "test_pairs_dict = get_dev_pairs_dict(test_pairs)\n",
    "n_test_batches = len(test_pairs) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "4000 19000 1950\n"
     ]
    }
   ],
   "source": [
    "# Read json file for relation to ID\n",
    "import json\n",
    "with open(\"./data/nyt2/relToId.json\", \"r\") as f:\n",
    "    relToId = json.load(f)\n",
    "\n",
    "# Read data for fine tuning\n",
    "trainNonNA = []\n",
    "for j in range(4):\n",
    "    with open(\"saved/aucs/train_preds/pcnn_att_nyt2_none_53_n_0_0.3455_NonNA_{}__preds.csv\".format(j), \"r\") as f:\n",
    "        data = pd.read_csv(f1, prefix = \"col\", header = None)\n",
    "        trainNonNA_ = data.col0.tolist()\n",
    "        relsNonNa_ = [\"#\" + str(relToId[rel]) for rel in data.col2.tolist()]\n",
    "        for i in range(len(trainNonNA_)):\n",
    "            trainNonNA_[i] = trainNonNA_[i] + relsNonNa_[i]\n",
    "        trainNonNA.extend(trainNonNA_)\n",
    "\n",
    "trainNA = []\n",
    "for j in range(1, 20):\n",
    "    if j%5 == 0:\n",
    "        print(j)\n",
    "    with open(\"saved/aucs/train_preds/pcnn_att_nyt2_none_53_n_0_0.3455_NA_{}__preds.csv\".format(j), \"r\") as f:\n",
    "        data = pd.read_csv(f, prefix = \"col\", header = None)\n",
    "    trainNA.extend([k + \"#0\" for k in data.col0.tolist()])\n",
    "all_pairs = pairs\n",
    "pairs = trainNA + trainNonNA\n",
    "random.shuffle(pairs)\n",
    "n_train_batches = len(pairs) // batch_size\n",
    "not_NA_rels = 1950\n",
    "print(len(trainNonNA), len(trainNA), not_NA_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_vs_loss(model, start):\n",
    "    random.shuffle(pairs)\n",
    "    increments = 30\n",
    "    no = 5 * increments\n",
    "    split_pairs = [pairs[i * batch_size : (i + 1) * batch_size] for i in range(no)]\n",
    "    x, y = model.print_lr_los(split_pairs, train_data, increments, start)\n",
    "    seaborn.lineplot([math.log10(k) for k in x], y)\n",
    "\n",
    "def test_model(batches, pairs, pairs_dict, processed_data, print_vals = False):\n",
    "    test_res = []\n",
    "    for i in range(batches):\n",
    "        batch_keys = pairs[i * batch_size : (i + 1) * batch_size]\n",
    "        words, pos1, pos2, inst_rels, masks, lengths, \\\n",
    "          rels, scope = batch_maker(processed_data, batch_keys)\n",
    "        \n",
    "        output, _ = model.test_batch(words, pos1, pos2, inst_rels, \n",
    "          masks, lengths, rels, scope)\n",
    "\n",
    "        for i, k in enumerate(batch_keys):\n",
    "            entPair = \"#\".join(k.split(\"#\")[:2])\n",
    "            entPairRels = pairs_dict[entPair]\n",
    "            for j in range(1, max_classes):\n",
    "                correct = 0\n",
    "                if j in entPairRels:\n",
    "                    correct = 1\n",
    "                test_res.append({\"entPair\" : entPair, \"actual\" : entPairRels, \"predicted\" : j,\n",
    "                  \"score\" : output[i][j], \"correct\" : correct})\n",
    "    prec = []\n",
    "    recall = []\n",
    "    correct = 0\n",
    "    sorted_test_result = sorted(test_res, key=lambda x: x['score'], reverse = True)\n",
    "\n",
    "    import time\n",
    "    start = time.time()\n",
    "    if print_vals:\n",
    "        for item in sorted_test_result[:100]:\n",
    "            print(item[\"entPair\"], item[\"actual\"], item[\"predicted\"], end=' -!-')\n",
    "\n",
    "    \n",
    "    for i, item in enumerate(sorted_test_result):\n",
    "        if item[\"correct\"]:\n",
    "            correct += 1  \n",
    "        prec.append(float(correct) / (i + 1))\n",
    "        recall.append(float(correct) / not_NA_rels)\n",
    "    auc = sklearn.metrics.auc(x = recall, y = prec)\n",
    "    end = time.time()\n",
    "    global best_auc\n",
    "    if auc > best_auc:\n",
    "        fname = fname_prefix + str(best_auc)[:6]\n",
    "        if os.path.exists(fname):\n",
    "           os.remove(fanme) \n",
    "        best_auc = auc\n",
    "        fname = fname_prefix + str(auc)[:6] \n",
    "        print(\"Saving model {}\".format(fname))\n",
    "        model.msaver(os.path.join(\"saved\", \"models\", fname))\n",
    "    return auc\n",
    "\n",
    "def train_epoch(pairs, epoch_no, learning_rate, model):\n",
    "    losses = []\n",
    "    aucs = []\n",
    "    print(\"Setting learning rate for the epoch no {} to : {}\".format(epoch_no, learning_rate))\n",
    "    n_batches = len(pairs) // batch_size\n",
    "    print(\"No of batches : {} \\n \".format(n_batches))\n",
    "    curr_pairs = pairs\n",
    "    for i in range(n_batches):\n",
    "        if i % 100 == 0:\n",
    "            sys.stdout.write(\"\\033[K\")\n",
    "            print(\"Running for batch : {}/{}\".format(i + 1, n_batches))\n",
    "        \n",
    "        batch_keys = curr_pairs[i * batch_size : (i + 1) * batch_size]\n",
    "        words, pos1, pos2, inst_rels, masks, lengths, \\\n",
    "            rels, scope = batch_maker(train_data, batch_keys)\n",
    "        loss_, x= model.train_batch(\n",
    "          words, pos1, pos2, inst_rels, masks, lengths,\n",
    "          rels, scope, learning_rate)\n",
    "\n",
    "        if loss_ > 10:\n",
    "            temp = []\n",
    "            for i in range(x.shape[0]):\n",
    "                for j in range(x.shape[1]):\n",
    "                    temp.append((x[i][j], i, j))\n",
    "            print(sorted(temp, reverse = True)[:100])\n",
    "            print(batch_keys[i])\n",
    "\n",
    "        if i%500 == 250:\n",
    "            print(i, end = \" \")\n",
    "            losses.append(loss_)\n",
    "            auc1 = test_model(n_test_batches, test_pairs, test_pairs_dict, test_data)\n",
    "            print(\"Test AUC : \", auc1)\n",
    "            aucs.append(auc1)\n",
    "\n",
    "    print(\"Testing after epoch : \")\n",
    "    auc1 = test_model(n_test_batches, test_pairs, test_pairs_dict, test_data)\n",
    "    print(\"Test Auc : \", auc1)\n",
    "    aucs.append(auc1)\n",
    "    return losses, aucs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model with encoder and selector :  pcnn att\n",
      "121 (?, 120, 230)\n",
      "121 (?, 120, 230)\n",
      "(?, 690)\n",
      "Created model with no bootstrapping, bs val : 0.0\n",
      "Train vars last :  [<tf.Variable 'attention/logit/relation_matrix:0' shape=(53, 690) dtype=float32_ref>, <tf.Variable 'attention/logit/bias:0' shape=(53,) dtype=float32_ref>]\n",
      "Train vars others :  [<tf.Variable 'word_embedding/word_embedding:0' shape=(114042, 50) dtype=float32_ref>, <tf.Variable 'word_embedding/unk_word_embedding:0' shape=(1, 50) dtype=float32_ref>, <tf.Variable 'word_embedding/start_word_embedding:0' shape=(1, 50) dtype=float32_ref>, <tf.Variable 'word_embedding/end_word_embedding:0' shape=(1, 50) dtype=float32_ref>, <tf.Variable 'pos_embedding/real_pos1_embedding:0' shape=(240, 5) dtype=float32_ref>, <tf.Variable 'pos_embedding/real_pos2_embedding:0' shape=(240, 5) dtype=float32_ref>, <tf.Variable 'pcnn/conv1d/kernel:0' shape=(3, 60, 230) dtype=float32_ref>, <tf.Variable 'pcnn/conv1d/bias:0' shape=(230,) dtype=float32_ref>]\n",
      "Loded model from path : saved/models/pcnn_att_nyt2_none_53_n_0_0.3386\n",
      "INFO:tensorflow:Restoring parameters from saved/models/pcnn_att_nyt2_none_53_n_0_0.3386\n",
      "Resetting adam optimizer variables.\n"
     ]
    }
   ],
   "source": [
    "check_pt = \"pcnn_att_nyt2_none_53_n_0_0.3386\"\n",
    "tf.reset_default_graph()\n",
    "model = ModelFt(\n",
    "    word_vec_mat, \n",
    "    encoder = encoder, \n",
    "    selector = selector, \n",
    "    l2_lambda = l2_lambd, \n",
    "    no_of_classes = max_classes, load_logit=False)\n",
    "model.mloader(os.path.join(\"saved\", \"models\", check_pt))\n",
    "model.reset_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving temp model\n",
      "Restoring temp model\n",
      "INFO:tensorflow:Restoring parameters from /tmp/abcd\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_vs_loss(model, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with all data.\n",
      "Setting learning rate for the epoch no 1 to : 0.001\n",
      "No of batches : 2192 \n",
      " \n",
      "\u001b[KRunning for batch : 1/2192\n",
      "\u001b[KRunning for batch : 101/2192\n",
      "\u001b[KRunning for batch : 201/2192\n",
      "250 Test AUC :  0.2243365062336267\n",
      "\u001b[KRunning for batch : 301/2192\n",
      "\u001b[KRunning for batch : 401/2192\n",
      "\u001b[KRunning for batch : 501/2192\n",
      "\u001b[KRunning for batch : 601/2192\n",
      "\u001b[KRunning for batch : 701/2192\n",
      "750 Test AUC :  0.29727721355513764\n",
      "\u001b[KRunning for batch : 801/2192\n",
      "\u001b[KRunning for batch : 901/2192\n",
      "\u001b[KRunning for batch : 1001/2192\n",
      "\u001b[KRunning for batch : 1101/2192\n",
      "\u001b[KRunning for batch : 1201/2192\n",
      "1250 Test AUC :  0.31851237965881884\n",
      "\u001b[KRunning for batch : 1301/2192\n",
      "\u001b[KRunning for batch : 1401/2192\n",
      "\u001b[KRunning for batch : 1501/2192\n",
      "\u001b[KRunning for batch : 1601/2192\n",
      "\u001b[KRunning for batch : 1701/2192\n",
      "1750 Test AUC :  0.313884982079891\n",
      "\u001b[KRunning for batch : 1801/2192\n",
      "\u001b[KRunning for batch : 1901/2192\n",
      "\u001b[KRunning for batch : 2001/2192\n",
      "\u001b[KRunning for batch : 2101/2192\n",
      "Testing after epoch : \n",
      "Test Auc :  0.3189055401357585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.16152012, 0.15178086, 0.10531716, 0.13332862],\n",
       " [0.2243365062336267,\n",
       "  0.29727721355513764,\n",
       "  0.31851237965881884,\n",
       "  0.313884982079891,\n",
       "  0.3189055401357585])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training with all data.\")\n",
    "train_epoch(all_pairs[:len(all_pairs) // 2], 1, 1e-3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate for the epoch no 1 to : 0.001\n",
      "No of batches : 359 \n",
      " \n",
      "\u001b[KRunning for batch : 1/359\n",
      "\u001b[KRunning for batch : 101/359\n",
      "\u001b[KRunning for batch : 201/359\n",
      "250 Test AUC :  0.28775806865752196\n",
      "\u001b[KRunning for batch : 301/359\n",
      "Testing after epoch : \n",
      "Test Auc :  0.2873739698493008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.00224147], [0.28775806865752196, 0.2873739698493008])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(pairs, 1, 1e-3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate for the epoch no 2 to : 0.001\n",
      "No of batches : 2192 \n",
      " \n",
      "\u001b[KRunning for batch : 1/2192\n",
      "\u001b[KRunning for batch : 101/2192\n",
      "\u001b[KRunning for batch : 201/2192\n",
      "250 Test AUC :  0.32765615855546393\n",
      "\u001b[KRunning for batch : 301/2192\n",
      "\u001b[KRunning for batch : 401/2192\n",
      "\u001b[KRunning for batch : 501/2192\n",
      "\u001b[KRunning for batch : 601/2192\n",
      "\u001b[KRunning for batch : 701/2192\n",
      "750 Test AUC :  0.32790966914867115\n",
      "\u001b[KRunning for batch : 801/2192\n",
      "\u001b[KRunning for batch : 901/2192\n",
      "\u001b[KRunning for batch : 1001/2192\n",
      "\u001b[KRunning for batch : 1101/2192\n",
      "\u001b[KRunning for batch : 1201/2192\n",
      "1250 Test AUC :  0.3082702666139706\n",
      "\u001b[KRunning for batch : 1301/2192\n",
      "\u001b[KRunning for batch : 1401/2192\n",
      "\u001b[KRunning for batch : 1501/2192\n",
      "\u001b[KRunning for batch : 1601/2192\n",
      "\u001b[KRunning for batch : 1701/2192\n",
      "1750 Test AUC :  0.3405799017308831\n",
      "\u001b[KRunning for batch : 1801/2192\n",
      "\u001b[KRunning for batch : 1901/2192\n",
      "\u001b[KRunning for batch : 2001/2192\n",
      "\u001b[KRunning for batch : 2101/2192\n",
      "Testing after epoch : \n",
      "Test Auc :  0.33787259069607256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.11876035, 0.12948889, 0.10471433, 0.09758467],\n",
       " [0.32765615855546393,\n",
       "  0.32790966914867115,\n",
       "  0.3082702666139706,\n",
       "  0.3405799017308831,\n",
       "  0.33787259069607256])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(all_pairs[len(all_pairs) // 2:], 2, 1e-3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate for the epoch no 1 to : 0.001\n",
      "No of batches : 359 \n",
      " \n",
      "\u001b[KRunning for batch : 1/359\n",
      "\u001b[KRunning for batch : 101/359\n",
      "\u001b[KRunning for batch : 201/359\n",
      "250 Test AUC :  0.30973568923026384\n",
      "\u001b[KRunning for batch : 301/359\n",
      "Testing after epoch : \n",
      "Test Auc :  0.30917041368629866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0011228989], [0.30973568923026384, 0.30917041368629866])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(pairs, 1, 1e-3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate for the epoch no 1 to : 0.001\n",
      "No of batches : 2192 \n",
      " \n",
      "\u001b[KRunning for batch : 1/2192\n",
      "\u001b[KRunning for batch : 101/2192\n",
      "\u001b[KRunning for batch : 201/2192\n",
      "250 Test AUC :  0.3322176669327207\n",
      "\u001b[KRunning for batch : 301/2192\n",
      "\u001b[KRunning for batch : 401/2192\n",
      "\u001b[KRunning for batch : 501/2192\n",
      "\u001b[KRunning for batch : 601/2192\n",
      "\u001b[KRunning for batch : 701/2192\n",
      "750 Test AUC :  0.3270888268407956\n",
      "\u001b[KRunning for batch : 801/2192\n",
      "\u001b[KRunning for batch : 901/2192\n",
      "\u001b[KRunning for batch : 1001/2192\n",
      "\u001b[KRunning for batch : 1101/2192\n",
      "\u001b[KRunning for batch : 1201/2192\n",
      "1250 Test AUC :  0.3278238865312191\n",
      "\u001b[KRunning for batch : 1301/2192\n",
      "\u001b[KRunning for batch : 1401/2192\n",
      "\u001b[KRunning for batch : 1501/2192\n",
      "\u001b[KRunning for batch : 1601/2192\n",
      "\u001b[KRunning for batch : 1701/2192\n",
      "1750 Test AUC :  0.3280877631281356\n",
      "\u001b[KRunning for batch : 1801/2192\n",
      "\u001b[KRunning for batch : 1901/2192\n",
      "\u001b[KRunning for batch : 2001/2192\n",
      "\u001b[KRunning for batch : 2101/2192\n",
      "Testing after epoch : \n",
      "Test Auc :  0.33229537895272343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.10762696, 0.17016278, 0.042928748, 0.12298589],\n",
       " [0.3322176669327207,\n",
       "  0.3270888268407956,\n",
       "  0.3278238865312191,\n",
       "  0.3280877631281356,\n",
       "  0.33229537895272343])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(all_pairs[:len(all_pairs) // 2], 1, 1e-3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate for the epoch no 1 to : 0.001\n",
      "No of batches : 359 \n",
      " \n",
      "\u001b[KRunning for batch : 1/359\n",
      "\u001b[KRunning for batch : 101/359\n",
      "\u001b[KRunning for batch : 201/359\n",
      "250 Test AUC :  0.31209249097784914\n",
      "\u001b[KRunning for batch : 301/359\n",
      "Testing after epoch : \n",
      "Test Auc :  0.3101978692498739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0016218817], [0.31209249097784914, 0.3101978692498739])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(pairs, 1, 1e-3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting learning rate for the epoch no 2 to : 0.001\n",
      "No of batches : 2192 \n",
      " \n",
      "\u001b[KRunning for batch : 1/2192\n",
      "\u001b[KRunning for batch : 101/2192\n",
      "\u001b[KRunning for batch : 201/2192\n",
      "250 Test AUC :  0.33231717911356284\n",
      "\u001b[KRunning for batch : 301/2192\n",
      "\u001b[KRunning for batch : 401/2192\n",
      "\u001b[KRunning for batch : 501/2192\n",
      "\u001b[KRunning for batch : 601/2192\n",
      "\u001b[KRunning for batch : 701/2192\n",
      "750 Test AUC :  0.33023730333686935\n",
      "\u001b[KRunning for batch : 801/2192\n",
      "\u001b[KRunning for batch : 901/2192\n",
      "\u001b[KRunning for batch : 1001/2192\n",
      "\u001b[KRunning for batch : 1101/2192\n",
      "\u001b[KRunning for batch : 1201/2192\n",
      "1250 Test AUC :  0.3053215873445218\n",
      "\u001b[KRunning for batch : 1301/2192\n",
      "\u001b[KRunning for batch : 1401/2192\n",
      "\u001b[KRunning for batch : 1501/2192\n",
      "\u001b[KRunning for batch : 1601/2192\n",
      "\u001b[KRunning for batch : 1701/2192\n",
      "1750 Test AUC :  0.3310073064622209\n",
      "\u001b[KRunning for batch : 1801/2192\n",
      "\u001b[KRunning for batch : 1901/2192\n",
      "\u001b[KRunning for batch : 2001/2192\n",
      "\u001b[KRunning for batch : 2101/2192\n",
      "Testing after epoch : \n",
      "Test Auc :  0.3369745040978908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.06464577, 0.091266036, 0.1273012, 0.06926124],\n",
       " [0.33231717911356284,\n",
       "  0.33023730333686935,\n",
       "  0.3053215873445218,\n",
       "  0.3310073064622209,\n",
       "  0.3369745040978908])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(all_pairs[len(all_pairs) // 2:], 2, 1e-3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
